"""
TTS Story Generator - Phi√™n b·∫£n ƒë·∫ßy ƒë·ªß v·ªõi t·∫•t c·∫£ c√°c tab
"""

import streamlit as st
import edge_tts
import os
import re
import asyncio
import tempfile
import json
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import natsort
import base64

# ==================== C·∫§U H√åNH ====================
st.set_page_config(
    page_title="TTS Story Generator Pro",
    page_icon="üìñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== C√ÅC CLASS CH√çNH ====================
class TextPreprocessor:
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """L√†m s·∫°ch vƒÉn b·∫£n"""
        if not text:
            return ""
        
        # Chu·∫©n h√≥a k√Ω t·ª±
        replacements = {
            '‚Äô': "'", '‚Äò': "'", '¬¥': "'", '`': "'",
            'ÔºÇ': '"', 'ÔºÇ': '"', '‚Äú': '"', '‚Äù': '"',
            '‚Ä¶': '...', '‚Äì': '-', '‚Äî': '-', 'ÔΩû': '~'
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n\s*\n', '\n\n', text)
        
        return text.strip()
    
    @staticmethod
    def split_into_lines(text: str) -> List[str]:
        """T√°ch vƒÉn b·∫£n th√†nh c√°c d√≤ng"""
        return [line.strip() for line in text.split('\n') if line.strip()]
    
    @staticmethod
    def parse_dialogues(text: str, prefixes: List[str]) -> List[Tuple[str, str]]:
        """Ph√¢n t√≠ch h·ªôi tho·∫°i v·ªõi c√°c prefix"""
        dialogues = []
        current_speaker = None
        current_text = []
        
        for line in text.split('\n'):
            line = line.strip()
            if not line:
                continue
            
            # Ki·ªÉm tra prefix
            found_prefix = None
            for prefix in prefixes:
                if line.lower().startswith(prefix.lower() + ':'):
                    found_prefix = prefix
                    break
            
            if found_prefix:
                if current_speaker is not None:
                    dialogues.append((current_speaker, ' '.join(current_text)))
                current_speaker = found_prefix
                content = line[len(found_prefix)+1:].strip()
                current_text = [content] if content else []
            elif current_speaker is not None:
                current_text.append(line)
        
        if current_speaker is not None and current_text:
            dialogues.append((current_speaker, ' '.join(current_text)))
        
        return dialogues

class AudioProcessor:
    """X·ª≠ l√Ω audio"""
    
    @staticmethod
    def enhance_audio(audio_path: str, volume: int = 100) -> str:
        """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng audio"""
        try:
            audio = AudioSegment.from_file(audio_path)
            
            # ƒêi·ªÅu ch·ªânh volume
            if volume != 100:
                change_in_db = volume - 100
                if change_in_db != 0:
                    audio = audio + change_in_db
            
            # Chu·∫©n h√≥a
            audio = normalize(audio)
            
            # N√©n ƒë·ªông
            audio = compress_dynamic_range(audio)
            
            # Th√™m fade
            audio = audio.fade_in(50).fade_out(50)
            
            # L∆∞u file m·ªõi
            enhanced_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3').name
            audio.export(enhanced_path, format='mp3', bitrate='256k')
            
            return enhanced_path
            
        except Exception as e:
            st.error(f"L·ªói x·ª≠ l√Ω audio: {str(e)}")
            return audio_path
    
    @staticmethod
    def merge_audios(audio_paths: List[str], pause_duration: int = 500) -> str:
        """Gh√©p nhi·ªÅu audio v·ªõi kho·∫£ng ngh·ªâ"""
        if not audio_paths:
            return None
        
        if len(audio_paths) == 1:
            return audio_paths[0]
        
        try:
            merged = AudioSegment.empty()
            pause = AudioSegment.silent(duration=pause_duration)
            
            for i, audio_path in enumerate(audio_paths):
                audio = AudioSegment.from_file(audio_path)
                merged += audio
                
                if i < len(audio_paths) - 1:
                    merged += pause
            
            merged_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3').name
            merged.export(merged_path, format='mp3', bitrate='256k')
            
            return merged_path
            
        except Exception as e:
            st.error(f"L·ªói gh√©p audio: {str(e)}")
            return None

class TTSEngine:
    """Engine TTS ch√≠nh"""
    
    # Danh s√°ch gi·ªçng ƒë·∫ßy ƒë·ªß
    VOICES = {
        "Ti·∫øng Vi·ªát": [
            {"id": "vi-VN-HoaiMyNeural", "name": "Ho√†i My", "gender": "N·ªØ"},
            {"id": "vi-VN-NamMinhNeural", "name": "Nam Minh", "gender": "Nam"}
        ],
        "English (US)": [
            {"id": "en-US-JennyNeural", "name": "Jenny", "gender": "N·ªØ"},
            {"id": "en-US-GuyNeural", "name": "Guy", "gender": "Nam"},
            {"id": "en-US-AvaNeural", "name": "Ava", "gender": "N·ªØ"},
            {"id": "en-US-AndrewNeural", "name": "Andrew", "gender": "Nam"},
            {"id": "en-US-EmmaNeural", "name": "Emma", "gender": "N·ªØ"},
            {"id": "en-US-BrianNeural", "name": "Brian", "gender": "Nam"},
            {"id": "en-US-AnaNeural", "name": "Ana", "gender": "N·ªØ"}
        ],
        "English (UK)": [
            {"id": "en-GB-LibbyNeural", "name": "Libby", "gender": "N·ªØ"},
            {"id": "en-GB-MiaNeural", "name": "Mia", "gender": "N·ªØ"},
            {"id": "en-GB-RyanNeural", "name": "Ryan", "gender": "Nam"},
            {"id": "en-GB-SoniaNeural", "name": "Sonia", "gender": "N·ªØ"}
        ]
    }
    
    def __init__(self):
        self.text_processor = TextPreprocessor()
        self.audio_processor = AudioProcessor()
    
    async def generate_speech(
        self,
        text: str,
        voice_id: str,
        rate: int = 0,
        pitch: int = 0,
        volume: int = 100
    ) -> Optional[str]:
        """T·∫°o gi·ªçng n√≥i t·ª´ vƒÉn b·∫£n"""
        try:
            if not text or not text.strip():
                return None
            
            # Format parameters
            rate_str = f"{rate:+d}%"
            pitch_str = f"{pitch:+d}Hz"
            
            # T·∫°o file t·∫°m
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
            temp_file.close()
            
            # Generate speech
            communicate = edge_tts.Communicate(
                text=text,
                voice=voice_id,
                rate=rate_str,
                pitch=pitch_str
            )
            
            await communicate.save(temp_file.name)
            
            # C·∫£i thi·ªán audio
            enhanced_file = self.audio_processor.enhance_audio(temp_file.name, volume)
            
            # X√≥a file t·∫°m g·ªëc
            try:
                os.unlink(temp_file.name)
            except:
                pass
            
            return enhanced_file
            
        except Exception as e:
            st.error(f"L·ªói t·∫°o gi·ªçng n√≥i: {str(e)}")
            return None

# ==================== C√ÅC PROCESSOR CHO T·ª™NG TAB ====================
class SingleCharacterProcessor:
    """X·ª≠ l√Ω cho tab 1 nh√¢n v·∫≠t"""
    
    def __init__(self, tts_engine: TTSEngine):
        self.tts_engine = tts_engine
    
    async def process(
        self,
        content: str,
        voice_id: str,
        rate: int,
        pitch: int,
        volume: int,
        pause: int,
        save_settings: bool = False
    ) -> Tuple[Optional[str], str]:
        """X·ª≠ l√Ω n·ªôi dung 1 nh√¢n v·∫≠t"""
        try:
            # T√°ch th√†nh c√°c d√≤ng
            lines = self.tts_engine.text_processor.split_into_lines(content)
            
            if not lines:
                return None, "‚ùå Kh√¥ng c√≥ n·ªôi dung ƒë·ªÉ x·ª≠ l√Ω"
            
            # T·∫°o audio cho t·ª´ng d√≤ng
            audio_files = []
            
            for i, line in enumerate(lines):
                audio_file = await self.tts_engine.generate_speech(
                    text=line,
                    voice_id=voice_id,
                    rate=rate,
                    pitch=pitch,
                    volume=volume
                )
                
                if audio_file:
                    audio_files.append(audio_file)
            
            if not audio_files:
                return None, "‚ùå Kh√¥ng t·∫°o ƒë∆∞·ª£c file √¢m thanh"
            
            # Gh√©p c√°c audio l·∫°i
            merged_audio = self.tts_engine.audio_processor.merge_audios(audio_files, pause)
            
            if merged_audio:
                # X√≥a c√°c file t·∫°m ri√™ng l·∫ª
                for file in audio_files:
                    try:
                        os.unlink(file)
                    except:
                        pass
                
                return merged_audio, "‚úÖ Ho√†n th√†nh! B·∫•m v√†o n√∫t ph√°t ƒë·ªÉ nghe"
            else:
                return None, "‚ùå Kh√¥ng th·ªÉ gh√©p audio"
                
        except Exception as e:
            return None, f"‚ùå L·ªói: {str(e)}"

class MultiCharacterProcessor:
    """X·ª≠ l√Ω cho tab ƒëa nh√¢n v·∫≠t"""
    
    def __init__(self, tts_engine: TTSEngine):
        self.tts_engine = tts_engine
    
    def parse_story(self, content: str) -> List[Tuple[str, str]]:
        """Ph√¢n t√≠ch c√¢u chuy·ªán ƒëa nh√¢n v·∫≠t"""
        dialogues = []
        current_character = None
        current_text = []
        
        for line in content.split('\n'):
            line = line.strip()
            if not line:
                continue
            
            # Ki·ªÉm tra c√°c prefix
            prefixes = ["CHAR1:", "CHAR2:", "CHAR3:", "NARRATOR:"]
            found_prefix = None
            
            for prefix in prefixes:
                if line.upper().startswith(prefix):
                    found_prefix = prefix.rstrip(':')
                    break
            
            if found_prefix:
                if current_character is not None:
                    dialogues.append((current_character, ' '.join(current_text)))
                current_character = found_prefix
                content = line[len(found_prefix)+1:].strip()
                current_text = [content] if content else []
            elif current_character is not None:
                current_text.append(line)
        
        if current_character is not None and current_text:
            dialogues.append((current_character, ' '.join(current_text)))
        
        return dialogues
    
    async def process(
        self,
        content: str,
        char1_voice: str,
        char2_voice: str,
        char3_voice: str,
        char1_rate: int,
        char2_rate: int,
        char3_rate: int,
        char1_pitch: int,
        char2_pitch: int,
        char3_pitch: int,
        char1_volume: int,
        char2_volume: int,
        char3_volume: int,
        repeat_times: int,
        pause_between: int,
        save_settings: bool = False
    ) -> Tuple[Optional[str], str]:
        """X·ª≠ l√Ω n·ªôi dung ƒëa nh√¢n v·∫≠t"""
        try:
            # Ph√¢n t√≠ch c√¢u chuy·ªán
            dialogues = self.parse_story(content)
            
            if not dialogues:
                return None, "‚ùå Kh√¥ng c√≥ n·ªôi dung h·ªôi tho·∫°i"
            
            # T·∫°o audio cho t·ª´ng ƒëo·∫°n
            audio_files = []
            
            for character, text in dialogues:
                # Ch·ªçn gi·ªçng d·ª±a tr√™n nh√¢n v·∫≠t
                if character == "CHAR1":
                    voice_id = char1_voice
                    rate = char1_rate
                    pitch = char1_pitch
                    volume = char1_volume
                elif character == "CHAR2":
                    voice_id = char2_voice
                    rate = char2_rate
                    pitch = char2_pitch
                    volume = char2_volume
                elif character == "CHAR3":
                    voice_id = char3_voice
                    rate = char3_rate
                    pitch = char3_pitch
                    volume = char3_volume
                else:  # NARRATOR
                    voice_id = char1_voice  # M·∫∑c ƒë·ªãnh d√πng gi·ªçng CHAR1
                    rate = char1_rate
                    pitch = char1_pitch
                    volume = char1_volume
                
                audio_file = await self.tts_engine.generate_speech(
                    text=text,
                    voice_id=voice_id,
                    rate=rate,
                    pitch=pitch,
                    volume=volume
                )
                
                if audio_file:
                    audio_files.append(audio_file)
            
            if not audio_files:
                return None, "‚ùå Kh√¥ng t·∫°o ƒë∆∞·ª£c file √¢m thanh"
            
            # L·∫∑p l·∫°i n·∫øu c·∫ßn
            if repeat_times > 1:
                original_files = audio_files.copy()
                for _ in range(repeat_times - 1):
                    audio_files.extend(original_files)
            
            # Gh√©p c√°c audio l·∫°i
            merged_audio = self.tts_engine.audio_processor.merge_audios(audio_files, pause_between)
            
            if merged_audio:
                # X√≥a c√°c file t·∫°m ri√™ng l·∫ª
                for file in audio_files:
                    try:
                        os.unlink(file)
                    except:
                        pass
                
                return merged_audio, "‚úÖ Ho√†n th√†nh! B·∫•m v√†o n√∫t ph√°t ƒë·ªÉ nghe"
            else:
                return None, "‚ùå Kh√¥ng th·ªÉ gh√©p audio"
                
        except Exception as e:
            return None, f"‚ùå L·ªói: {str(e)}"

class DialogueProcessor:
    """X·ª≠ l√Ω cho tab h·ªèi ƒë√°p"""
    
    def __init__(self, tts_engine: TTSEngine):
        self.tts_engine = tts_engine
    
    def parse_dialogues(self, content: str) -> List[Tuple[str, str]]:
        """Ph√¢n t√≠ch h·ªôi tho·∫°i Q&A"""
        return self.tts_engine.text_processor.parse_dialogues(content, ["Q", "A"])
    
    async def process(
        self,
        content: str,
        voice_q: str,
        voice_a: str,
        rate_q: int,
        rate_a: int,
        pitch_q: int,
        pitch_a: int,
        volume_q: int,
        volume_a: int,
        repeat_times: int,
        pause_q: int,
        pause_a: int,
        save_settings: bool = False
    ) -> Tuple[Optional[str], str]:
        """X·ª≠ l√Ω h·ªôi tho·∫°i Q&A"""
        try:
            # Ph√¢n t√≠ch h·ªôi tho·∫°i
            dialogues = self.parse_dialogues(content)
            
            if not dialogues:
                return None, "‚ùå Kh√¥ng c√≥ n·ªôi dung h·ªôi tho·∫°i"
            
            # T·∫°o audio cho t·ª´ng c·∫∑p Q/A
            audio_files = []
            pause_durations = []
            
            for speaker, text in dialogues:
                # Ch·ªçn gi·ªçng d·ª±a tr√™n speaker
                if speaker.upper() == "Q":
                    voice_id = voice_q
                    rate = rate_q
                    pitch = pitch_q
                    volume = volume_q
                    next_pause = pause_q
                else:  # "A"
                    voice_id = voice_a
                    rate = rate_a
                    pitch = pitch_a
                    volume = volume_a
                    next_pause = pause_a
                
                audio_file = await self.tts_engine.generate_speech(
                    text=text,
                    voice_id=voice_id,
                    rate=rate,
                    pitch=pitch,
                    volume=volume
                )
                
                if audio_file:
                    audio_files.append(audio_file)
                    pause_durations.append(next_pause)
            
            if not audio_files:
                return None, "‚ùå Kh√¥ng t·∫°o ƒë∆∞·ª£c file √¢m thanh"
            
            # L·∫∑p l·∫°i n·∫øu c·∫ßn
            if repeat_times > 1:
                original_files = audio_files.copy()
                original_pauses = pause_durations.copy()
                for _ in range(repeat_times - 1):
                    audio_files.extend(original_files)
                    pause_durations.extend(original_pauses)
            
            # Gh√©p c√°c audio l·∫°i v·ªõi c√°c kho·∫£ng ngh·ªâ kh√°c nhau
            merged_audio = self.merge_with_variable_pauses(audio_files, pause_durations)
            
            if merged_audio:
                # X√≥a c√°c file t·∫°m ri√™ng l·∫ª
                for file in audio_files:
                    try:
                        os.unlink(file)
                    except:
                        pass
                
                return merged_audio, "‚úÖ Ho√†n th√†nh! B·∫•m v√†o n√∫t ph√°t ƒë·ªÉ nghe"
            else:
                return None, "‚ùå Kh√¥ng th·ªÉ gh√©p audio"
                
        except Exception as e:
            return None, f"‚ùå L·ªói: {str(e)}"
    
    def merge_with_variable_pauses(self, audio_files: List[str], pauses: List[int]) -> Optional[str]:
        """Gh√©p audio v·ªõi c√°c kho·∫£ng ngh·ªâ kh√°c nhau"""
        if not audio_files:
            return None
        
        try:
            merged = AudioSegment.empty()
            
            for i, audio_path in enumerate(audio_files):
                audio = AudioSegment.from_file(audio_path)
                merged += audio
                
                if i < len(audio_files) - 1 and i < len(pauses):
                    merged += AudioSegment.silent(duration=pauses[i])
            
            merged_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3').name
            merged.export(merged_path, format='mp3', bitrate='256k')
            
            return merged_path
            
        except Exception as e:
            st.error(f"L·ªói gh√©p audio: {str(e)}")
            return None

# ==================== STREAMLIT APP ====================
class TTSApp:
    """·ª®ng d·ª•ng Streamlit ch√≠nh"""
    
    def __init__(self):
        self.tts_engine = TTSEngine()
        self.single_processor = SingleCharacterProcessor(self.tts_engine)
        self.multi_processor = MultiCharacterProcessor(self.tts_engine)
        self.dialogue_processor = DialogueProcessor(self.tts_engine)
        self.init_session_state()
    
    def init_session_state(self):
        """Kh·ªüi t·∫°o session state"""
        defaults = {
            'history': [],
            'current_audio': None,
            'current_text': "",
            'mode': 'single',
            'settings_single': {
                "voice": "vi-VN-HoaiMyNeural",
                "rate": 0,
                "pitch": 0,
                "volume": 100,
                "pause": 500
            },
            'settings_multi': {
                "char1_voice": "vi-VN-HoaiMyNeural",
                "char2_voice": "vi-VN-NamMinhNeural",
                "char3_voice": "vi-VN-HoaiMyNeural",
                "char1_rate": -20,
                "char2_rate": -25,
                "char3_rate": -15,
                "char1_pitch": 0,
                "char2_pitch": 0,
                "char3_pitch": 0,
                "char1_volume": 100,
                "char2_volume": 100,
                "char3_volume": 100,
                "repeat_times": 1,
                "pause_between": 500
            },
            'settings_dialogue': {
                "voice_q": "vi-VN-HoaiMyNeural",
                "voice_a": "vi-VN-NamMinhNeural",
                "rate_q": -20,
                "rate_a": -25,
                "pitch_q": 0,
                "pitch_a": 0,
                "volume_q": 100,
                "volume_a": 100,
                "repeat_times": 2,
                "pause_q": 200,
                "pause_a": 500
            }
        }
        
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value
    
    def get_voice_display_name(self, voice_id: str) -> str:
        """L·∫•y t√™n hi·ªÉn th·ªã c·ªßa gi·ªçng"""
        for lang, voices in self.tts_engine.VOICES.items():
            for voice in voices:
                if voice["id"] == voice_id:
                    return f"{lang} - {voice['name']} ({voice['gender']})"
        return voice_id
    
    def render_sidebar(self):
        """Render sidebar"""
        with st.sidebar:
            st.title("üìñ TTS Story Generator")
            st.markdown("---")
            
            # Ch·ªçn tab
            mode = st.radio(
                "Ch·ªçn ch·∫ø ƒë·ªô",
                ["üé§ 1 Nh√¢n v·∫≠t", "üë• ƒêa nh√¢n v·∫≠t", "üí¨ H·ªèi & ƒê√°p"],
                key="mode_selector"
            )
            
            # Map mode
            mode_map = {
                "üé§ 1 Nh√¢n v·∫≠t": "single",
                "üë• ƒêa nh√¢n v·∫≠t": "multi",
                "üí¨ H·ªèi & ƒê√°p": "dialogue"
            }
            st.session_state.mode = mode_map[mode]
            
            st.markdown("---")
            
            # C√†i ƒë·∫∑t chung
            with st.expander("‚öôÔ∏è Th√¥ng tin", expanded=False):
                st.caption("**Phi√™n b·∫£n:** 1.0.0")
                st.caption("**Edge TTS:** 7.2.0")
                st.caption("**H·ªó tr·ª£:** ƒêa ng√¥n ng·ªØ")
                st.caption("**ƒê·ªãnh d·∫°ng:** MP3")
            
            st.markdown("---")
            
            # History
            if st.session_state.history:
                with st.expander("üìú L·ªãch s·ª≠", expanded=False):
                    for i, item in enumerate(st.session_state.history[-3:][::-1]):
                        btn_text = f"{i+1}. {item['text'][:30]}..."
                        if st.button(btn_text, key=f"hist_{i}", use_container_width=True):
                            st.session_state.current_text = item['text']
                            st.rerun()
            
            st.markdown("---")
            st.caption("Made with ‚ù§Ô∏è by TTS Generator")
    
    def render_single_character_tab(self):
        """Tab 1: 1 Nh√¢n v·∫≠t"""
        st.header("üé§ 1 Nh√¢n v·∫≠t")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Input text
            content = st.text_area(
                "N·ªôi dung truy·ªán",
                value=st.session_state.current_text,
                height=300,
                placeholder="Nh·∫≠p n·ªôi dung truy·ªán (m·ªói d√≤ng l√† m·ªôt ƒëo·∫°n)...",
                key="single_content"
            )
            
            # Voice settings
            with st.expander("üéôÔ∏è C√†i ƒë·∫∑t gi·ªçng", expanded=True):
                languages = list(self.tts_engine.VOICES.keys())
                selected_lang = st.selectbox(
                    "Ng√¥n ng·ªØ",
                    languages,
                    index=0,
                    key="single_lang"
                )
                
                voices = self.tts_engine.VOICES[selected_lang]
                voice_options = {f"{v['name']} ({v['gender']})": v['id'] for v in voices}
                
                selected_voice_name = st.selectbox(
                    "Gi·ªçng ƒë·ªçc",
                    list(voice_options.keys()),
                    key="single_voice"
                )
                
                selected_voice_id = voice_options[selected_voice_name]
            
            # Audio settings
            with st.expander("üéõÔ∏è ƒêi·ªÅu ch·ªânh √¢m thanh", expanded=True):
                col_rate, col_pitch, col_volume = st.columns(3)
                with col_rate:
                    rate = st.slider("T·ªëc ƒë·ªô (%)", -30, 30, 0, key="single_rate")
                with col_pitch:
                    pitch = st.slider("Cao ƒë·ªô (Hz)", -30, 30, 0, key="single_pitch")
                with col_volume:
                    volume = st.slider("√Çm l∆∞·ª£ng (%)", 50, 150, 100, key="single_volume")
                
                pause = st.slider("Kho·∫£ng ngh·ªâ (ms)", 100, 2000, 500, key="single_pause")
            
            # Options
            save_settings = st.checkbox("L∆∞u c√†i ƒë·∫∑t", value=False, key="single_save")
            
            # Generate button
            if st.button("üé§ T·∫°o truy·ªán audio", type="primary", use_container_width=True):
                if not content.strip():
                    st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung")
                    return
                
                self.generate_single_character(
                    content=content,
                    voice_id=selected_voice_id,
                    rate=rate,
                    pitch=pitch,
                    volume=volume,
                    pause=pause,
                    save_settings=save_settings
                )
        
        with col2:
            self.render_audio_player()
    
    def render_multi_character_tab(self):
        """Tab 2: ƒêa nh√¢n v·∫≠t"""
        st.header("üë• ƒêa nh√¢n v·∫≠t")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Input text
            content = st.text_area(
                "N·ªôi dung c√¢u chuy·ªán",
                height=300,
                placeholder="CHAR1: L·ªùi tho·∫°i nh√¢n v·∫≠t 1\nCHAR2: L·ªùi tho·∫°i nh√¢n v·∫≠t 2\nCHAR3: L·ªùi tho·∫°i nh√¢n v·∫≠t 3\nNARRATOR: L·ªùi d·∫´n truy·ªán",
                key="multi_content"
            )
            
            # Character settings
            with st.expander("üé≠ C√†i ƒë·∫∑t nh√¢n v·∫≠t", expanded=True):
                st.subheader("Nh√¢n v·∫≠t 1 (CHAR1)")
                col_char1a, col_char1b = st.columns(2)
                with col_char1a:
                    char1_lang = st.selectbox(
                        "Ng√¥n ng·ªØ NV1",
                        list(self.tts_engine.VOICES.keys()),
                        index=0,
                        key="char1_lang"
                    )
                    voices = self.tts_engine.VOICES[char1_lang]
                    voice_options = {f"{v['name']} ({v['gender']})": v['id'] for v in voices}
                    char1_voice_name = st.selectbox("Gi·ªçng NV1", list(voice_options.keys()), key="char1_voice")
                    char1_voice = voice_options[char1_voice_name]
                with col_char1b:
                    char1_rate = st.slider("T·ªëc ƒë·ªô (%)", -30, 30, -20, key="char1_rate")
                    char1_volume = st.slider("√Çm l∆∞·ª£ng (%)", 50, 150, 100, key="char1_volume")
                
                st.subheader("Nh√¢n v·∫≠t 2 (CHAR2)")
                col_char2a, col_char2b = st.columns(2)
                with col_char2a:
                    char2_lang = st.selectbox(
                        "Ng√¥n ng·ªØ NV2",
                        list(self.tts_engine.VOICES.keys()),
                        index=0,
                        key="char2_lang"
                    )
                    voices = self.tts_engine.VOICES[char2_lang]
                    voice_options = {f"{v['name']} ({v['gender']})": v['id'] for v in voices}
                    char2_voice_name = st.selectbox("Gi·ªçng NV2", list(voice_options.keys()), key="char2_voice")
                    char2_voice = voice_options[char2_voice_name]
                with col_char2b:
                    char2_rate = st.slider("T·ªëc ƒë·ªô (%)", -30, 30, -25, key="char2_rate")
                    char2_volume = st.slider("√Çm l∆∞·ª£ng (%)", 50, 150, 100, key="char2_volume")
                
                st.subheader("Nh√¢n v·∫≠t 3 (CHAR3)")
                col_char3a, col_char3b = st.columns(2)
                with col_char3a:
                    char3_lang = st.selectbox(
                        "Ng√¥n ng·ªØ NV3",
                        list(self.tts_engine.VOICES.keys()),
                        index=0,
                        key="char3_lang"
                    )
                    voices = self.tts_engine.VOICES[char3_lang]
                    voice_options = {f"{v['name']} ({v['gender']})": v['id'] for v in voices}
                    char3_voice_name = st.selectbox("Gi·ªçng NV3", list(voice_options.keys()), key="char3_voice")
                    char3_voice = voice_options[char3_voice_name]
                with col_char3b:
                    char3_rate = st.slider("T·ªëc ƒë·ªô (%)", -30, 30, -15, key="char3_rate")
                    char3_volume = st.slider("√Çm l∆∞·ª£ng (%)", 50, 150, 100, key="char3_volume")
            
            # General settings
            with st.expander("üîÑ C√†i ƒë·∫∑t chung", expanded=False):
                repeat_times = st.slider("S·ªë l·∫ßn l·∫∑p", 1, 5, 1, key="multi_repeat")
                pause_between = st.slider("Kho·∫£ng ngh·ªâ (ms)", 100, 2000, 500, key="multi_pause")
                save_settings = st.checkbox("L∆∞u c√†i ƒë·∫∑t", value=False, key="multi_save")
            
            # Generate button
            if st.button("üéß T·∫°o c√¢u chuy·ªán audio", type="primary", use_container_width=True):
                if not content.strip():
                    st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung")
                    return
                
                self.generate_multi_character(
                    content=content,
                    char1_voice=char1_voice,
                    char2_voice=char2_voice,
                    char3_voice=char3_voice,
                    char1_rate=char1_rate,
                    char2_rate=char2_rate,
                    char3_rate=char3_rate,
                    char1_pitch=0,  # ƒê·ªÉ ƒë∆°n gi·∫£n
                    char2_pitch=0,
                    char3_pitch=0,
                    char1_volume=char1_volume,
                    char2_volume=char2_volume,
                    char3_volume=char3_volume,
                    repeat_times=repeat_times,
                    pause_between=pause_between,
                    save_settings=save_settings
                )
        
        with col2:
            self.render_audio_player()
    
    def render_dialogue_tab(self):
        """Tab 3: H·ªèi & ƒê√°p"""
        st.header("üí¨ H·ªèi & ƒê√°p")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Input text
            content = st.text_area(
                "N·ªôi dung h·ªôi tho·∫°i",
                height=300,
                placeholder="Q: C√¢u h·ªèi\nA: C√¢u tr·∫£ l·ªùi\nQ: C√¢u h·ªèi ti·∫øp theo\nA: C√¢u tr·∫£ l·ªùi ti·∫øp theo",
                key="dialogue_content"
            )
            
            # Voice settings for Q
            with st.expander("‚ùì Gi·ªçng c√¢u h·ªèi (Q)", expanded=True):
                q_lang = st.selectbox(
                    "Ng√¥n ng·ªØ c√¢u h·ªèi",
                    list(self.tts_engine.VOICES.keys()),
                    index=0,
                    key="q_lang"
                )
                voices = self.tts_engine.VOICES[q_lang]
                voice_options = {f"{v['name']} ({v['gender']})": v['id'] for v in voices}
                q_voice_name = st.selectbox("Gi·ªçng c√¢u h·ªèi", list(voice_options.keys()), key="q_voice")
                q_voice = voice_options[q_voice_name]
                
                col_q1, col_q2 = st.columns(2)
                with col_q1:
                    rate_q = st.slider("T·ªëc ƒë·ªô Q (%)", -30, 30, -20, key="rate_q")
                with col_q2:
                    volume_q = st.slider("√Çm l∆∞·ª£ng Q (%)", 50, 150, 100, key="volume_q")
            
            # Voice settings for A
            with st.expander("‚ùó Gi·ªçng c√¢u tr·∫£ l·ªùi (A)", expanded=True):
                a_lang = st.selectbox(
                    "Ng√¥n ng·ªØ c√¢u tr·∫£ l·ªùi",
                    list(self.tts_engine.VOICES.keys()),
                    index=0,
                    key="a_lang"
                )
                voices = self.tts_engine.VOICES[a_lang]
                voice_options = {f"{v['name']} ({v['gender']})": v['id'] for v in voices}
                a_voice_name = st.selectbox("Gi·ªçng c√¢u tr·∫£ l·ªùi", list(voice_options.keys()), key="a_voice")
                a_voice = voice_options[a_voice_name]
                
                col_a1, col_a2 = st.columns(2)
                with col_a1:
                    rate_a = st.slider("T·ªëc ƒë·ªô A (%)", -30, 30, -25, key="rate_a")
                with col_a2:
                    volume_a = st.slider("√Çm l∆∞·ª£ng A (%)", 50, 150, 100, key="volume_a")
            
            # General settings
            with st.expander("üîÑ C√†i ƒë·∫∑t l·∫∑p l·∫°i", expanded=False):
                repeat_times = st.slider("S·ªë l·∫ßn l·∫∑p", 1, 5, 2, key="dialogue_repeat")
                pause_q = st.slider("Ngh·ªâ sau c√¢u h·ªèi (ms)", 100, 1000, 200, key="pause_q")
                pause_a = st.slider("Ngh·ªâ sau c√¢u tr·∫£ l·ªùi (ms)", 100, 2000, 500, key="pause_a")
                save_settings = st.checkbox("L∆∞u c√†i ƒë·∫∑t", value=False, key="dialogue_save")
            
            # Generate button
            if st.button("üéß T·∫°o audio h·ªôi tho·∫°i", type="primary", use_container_width=True):
                if not content.strip():
                    st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung")
                    return
                
                self.generate_dialogue(
                    content=content,
                    voice_q=q_voice,
                    voice_a=a_voice,
                    rate_q=rate_q,
                    rate_a=rate_a,
                    pitch_q=0,  # ƒê·ªÉ ƒë∆°n gi·∫£n
                    pitch_a=0,
                    volume_q=volume_q,
                    volume_a=volume_a,
                    repeat_times=repeat_times,
                    pause_q=pause_q,
                    pause_a=pause_a,
                    save_settings=save_settings
                )
        
        with col2:
            self.render_audio_player()
    
    def generate_single_character(self, **kwargs):
        """T·∫°o audio cho 1 nh√¢n v·∫≠t"""
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                audio_file, message = loop.run_until_complete(
                    self.single_processor.process(**kwargs)
                )
                
                if audio_file:
                    st.session_state.current_audio = audio_file
                    st.session_state.current_text = kwargs['content']
                    
                    # L∆∞u v√†o history
                    history_item = {
                        "text": kwargs['content'][:100] + ("..." if len(kwargs['content']) > 100 else ""),
                        "mode": "single",
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    st.session_state.history.append(history_item)
                    
                    st.success(message)
                    st.balloons()
                    st.rerun()
                else:
                    st.error(message)
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
    
    def generate_multi_character(self, **kwargs):
        """T·∫°o audio cho ƒëa nh√¢n v·∫≠t"""
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                audio_file, message = loop.run_until_complete(
                    self.multi_processor.process(**kwargs)
                )
                
                if audio_file:
                    st.session_state.current_audio = audio_file
                    
                    # L∆∞u v√†o history
                    history_item = {
                        "text": kwargs['content'][:100] + ("..." if len(kwargs['content']) > 100 else ""),
                        "mode": "multi",
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    st.session_state.history.append(history_item)
                    
                    st.success(message)
                    st.balloons()
                    st.rerun()
                else:
                    st.error(message)
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
    
    def generate_dialogue(self, **kwargs):
        """T·∫°o audio cho h·ªôi tho·∫°i"""
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                audio_file, message = loop.run_until_complete(
                    self.dialogue_processor.process(**kwargs)
                )
                
                if audio_file:
                    st.session_state.current_audio = audio_file
                    
                    # L∆∞u v√†o history
                    history_item = {
                        "text": kwargs['content'][:100] + ("..." if len(kwargs['content']) > 100 else ""),
                        "mode": "dialogue",
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    st.session_state.history.append(history_item)
                    
                    st.success(message)
                    st.balloons()
                    st.rerun()
                else:
                    st.error(message)
                    
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
    
    def render_audio_player(self):
        """Hi·ªÉn th·ªã audio player"""
        if st.session_state.current_audio and os.path.exists(st.session_state.current_audio):
            # Audio player
            st.audio(st.session_state.current_audio, format="audio/mp3")
            
            # Th√¥ng tin
            with st.expander("üìä Th√¥ng tin file", expanded=True):
                file_size = os.path.getsize(st.session_state.current_audio) / 1024
                st.write(f"**K√≠ch th∆∞·ªõc:** {file_size:.1f} KB")
                st.write(f"**Th·ªùi gian t·∫°o:** {datetime.now().strftime('%H:%M:%S')}")
            
            # Download button
            with open(st.session_state.current_audio, "rb") as f:
                audio_bytes = f.read()
            
            st.download_button(
                label="üì• T·∫£i audio",
                data=audio_bytes,
                file_name=f"tts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3",
                mime="audio/mp3",
                use_container_width=True
            )
            
            # Clear button
            if st.button("üóëÔ∏è X√≥a file", use_container_width=True):
                try:
                    os.unlink(st.session_state.current_audio)
                except:
                    pass
                st.session_state.current_audio = None
                st.rerun()
        
        else:
            st.info("üëà **H∆∞·ªõng d·∫´n:**")
            st.markdown("""
            1. Ch·ªçn ch·∫ø ƒë·ªô ph√π h·ª£p
            2. Nh·∫≠p n·ªôi dung vƒÉn b·∫£n
            3. C·∫•u h√¨nh gi·ªçng n√≥i v√† c√†i ƒë·∫∑t
            4. Nh·∫•n n√∫t t·∫°o audio
            5. Nghe v√† t·∫£i v·ªÅ
            """)
    
    def run(self):
        """Ch·∫°y ·ª©ng d·ª•ng ch√≠nh"""
        # CSS t√πy ch·ªânh
        st.markdown("""
        <style>
        .stApp {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        .stButton > button {
            border-radius: 10px;
            font-weight: bold;
        }
        
        .stTextArea textarea {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3 {
            color: #1f77b4;
        }
        
        .tab-content {
            padding: 20px;
            background: #f8f9fa;
            border-radius: 15px;
            margin: 10px 0;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Header
        st.title("üìñ TTS Story Generator Pro")
        st.markdown("Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i v·ªõi 3 ch·∫ø ƒë·ªô kh√°c nhau")
        
        # Render sidebar
        self.render_sidebar()
        
        # Tabs
        tab1, tab2, tab3 = st.tabs(["üé§ 1 Nh√¢n v·∫≠t", "üë• ƒêa nh√¢n v·∫≠t", "üí¨ H·ªèi & ƒê√°p"])
        
        with tab1:
            self.render_single_character_tab()
        
        with tab2:
            self.render_multi_character_tab()
        
        with tab3:
            self.render_dialogue_tab()
        
        # Footer
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.caption("¬© 2024 TTS Generator")
        with col2:
            st.caption("Edge TTS 7.2.0")
        with col3:
            st.caption("Streamlit Cloud")

# ==================== MAIN ====================
def main():
    """H√†m ch√≠nh"""
    try:
        app = TTSApp()
        app.run()
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói: {str(e)}")
        st.info("Vui l√≤ng l√†m m·ªõi trang.")

if __name__ == "__main__":
    main()
